step 0: train loss: 4.4371, val loss: 4.4354
step 10: train loss: 3.4829, val loss: 3.4762
step 20: train loss: 3.2030, val loss: 3.1920
step 30: train loss: 3.0795, val loss: 3.0626
step 40: train loss: 2.9801, val loss: 2.9568
step 50: train loss: 2.8872, val loss: 2.8723
step 60: train loss: 2.8187, val loss: 2.8001
step 70: train loss: 2.7655, val loss: 2.7443
step 80: train loss: 2.7062, val loss: 2.6978
step 90: train loss: 2.6680, val loss: 2.6526
step 100: train loss: 2.6254, val loss: 2.6231
step 110: train loss: 2.6041, val loss: 2.6020
step 120: train loss: 2.5743, val loss: 2.5878
step 130: train loss: 2.5569, val loss: 2.5706
step 140: train loss: 2.5471, val loss: 2.5583
step 150: train loss: 2.5335, val loss: 2.5460
step 160: train loss: 2.5207, val loss: 2.5342
step 170: train loss: 2.5068, val loss: 2.5370
step 180: train loss: 2.4933, val loss: 2.5224
step 190: train loss: 2.4933, val loss: 2.5185
step 200: train loss: 2.4824, val loss: 2.5189
step 210: train loss: 2.4805, val loss: 2.5058
step 220: train loss: 2.4805, val loss: 2.5112
step 230: train loss: 2.4662, val loss: 2.5082
step 240: train loss: 2.4673, val loss: 2.5012
step 250: train loss: 2.4663, val loss: 2.4975
step 260: train loss: 2.4532, val loss: 2.4970
step 270: train loss: 2.4537, val loss: 2.4954
step 280: train loss: 2.4560, val loss: 2.4883
step 290: train loss: 2.4478, val loss: 2.4879
step 300: train loss: 2.4457, val loss: 2.4883
step 310: train loss: 2.4474, val loss: 2.4795
step 320: train loss: 2.4437, val loss: 2.4813
step 330: train loss: 2.4334, val loss: 2.4814
step 340: train loss: 2.4316, val loss: 2.4804
step 350: train loss: 2.4294, val loss: 2.4682
step 360: train loss: 2.4338, val loss: 2.4776
step 370: train loss: 2.4310, val loss: 2.4696
step 380: train loss: 2.4250, val loss: 2.4682
step 390: train loss: 2.4183, val loss: 2.4688
step 400: train loss: 2.4224, val loss: 2.4617
step 410: train loss: 2.4178, val loss: 2.4608
step 420: train loss: 2.4211, val loss: 2.4632
step 430: train loss: 2.4161, val loss: 2.4600
step 440: train loss: 2.4112, val loss: 2.4657
step 450: train loss: 2.4095, val loss: 2.4610
step 460: train loss: 2.4115, val loss: 2.4536
step 470: train loss: 2.4034, val loss: 2.4582
step 480: train loss: 2.4046, val loss: 2.4567
step 490: train loss: 2.4069, val loss: 2.4552
step 500: train loss: 2.3882, val loss: 2.4475
step 510: train loss: 2.4059, val loss: 2.4438
step 520: train loss: 2.3975, val loss: 2.4449
step 530: train loss: 2.3972, val loss: 2.4487
step 540: train loss: 2.3987, val loss: 2.4483
step 550: train loss: 2.3908, val loss: 2.4470
step 560: train loss: 2.3963, val loss: 2.4418
step 570: train loss: 2.3953, val loss: 2.4420
step 580: train loss: 2.3896, val loss: 2.4384
step 590: train loss: 2.3868, val loss: 2.4353
step 600: train loss: 2.3857, val loss: 2.4405
step 610: train loss: 2.3886, val loss: 2.4392
step 620: train loss: 2.3822, val loss: 2.4365
step 630: train loss: 2.3769, val loss: 2.4404
step 640: train loss: 2.3823, val loss: 2.4373
step 650: train loss: 2.3811, val loss: 2.4378
step 660: train loss: 2.3788, val loss: 2.4252
step 670: train loss: 2.3763, val loss: 2.4253
step 680: train loss: 2.3777, val loss: 2.4294
step 690: train loss: 2.3737, val loss: 2.4327
step 700: train loss: 2.3694, val loss: 2.4338
step 710: train loss: 2.3640, val loss: 2.4336
step 720: train loss: 2.3625, val loss: 2.4254
step 730: train loss: 2.3648, val loss: 2.4227
step 740: train loss: 2.3694, val loss: 2.4274
step 750: train loss: 2.3631, val loss: 2.4298
step 760: train loss: 2.3609, val loss: 2.4190
step 770: train loss: 2.3579, val loss: 2.4235
step 780: train loss: 2.3651, val loss: 2.4141
step 790: train loss: 2.3542, val loss: 2.4188
step 800: train loss: 2.3617, val loss: 2.4239
step 810: train loss: 2.3584, val loss: 2.4185
step 820: train loss: 2.3527, val loss: 2.4232
step 830: train loss: 2.3553, val loss: 2.4136
step 840: train loss: 2.3575, val loss: 2.4143
step 850: train loss: 2.3531, val loss: 2.4149
step 860: train loss: 2.3519, val loss: 2.4140
step 870: train loss: 2.3509, val loss: 2.4079
step 880: train loss: 2.3536, val loss: 2.4121
step 890: train loss: 2.3530, val loss: 2.4127
step 900: train loss: 2.3442, val loss: 2.4149
step 910: train loss: 2.3402, val loss: 2.4019
step 920: train loss: 2.3459, val loss: 2.4087
step 930: train loss: 2.3436, val loss: 2.4070
step 940: train loss: 2.3447, val loss: 2.4032
step 950: train loss: 2.3434, val loss: 2.4102
step 960: train loss: 2.3366, val loss: 2.4023
step 970: train loss: 2.3378, val loss: 2.4030
step 980: train loss: 2.3356, val loss: 2.4015
step 990: train loss: 2.3327, val loss: 2.3951
step 1000: train loss: 2.3305, val loss: 2.4012
step 1010: train loss: 2.3328, val loss: 2.3986
step 1020: train loss: 2.3308, val loss: 2.3936
step 1030: train loss: 2.3320, val loss: 2.3963
step 1040: train loss: 2.3275, val loss: 2.4016
step 1050: train loss: 2.3179, val loss: 2.3891
step 1060: train loss: 2.3211, val loss: 2.3802
step 1070: train loss: 2.3179, val loss: 2.3890
step 1080: train loss: 2.3201, val loss: 2.3927
step 1090: train loss: 2.3259, val loss: 2.3906
step 1100: train loss: 2.3137, val loss: 2.3843
step 1110: train loss: 2.3113, val loss: 2.3888
step 1120: train loss: 2.3067, val loss: 2.3805
step 1130: train loss: 2.3129, val loss: 2.3827
step 1140: train loss: 2.3075, val loss: 2.3821
step 1150: train loss: 2.3066, val loss: 2.3745
step 1160: train loss: 2.3008, val loss: 2.3811
step 1170: train loss: 2.2936, val loss: 2.3669
step 1180: train loss: 2.2880, val loss: 2.3706
step 1190: train loss: 2.2876, val loss: 2.3678
step 1200: train loss: 2.2919, val loss: 2.3687
step 1210: train loss: 2.2824, val loss: 2.3641
step 1220: train loss: 2.2832, val loss: 2.3627
step 1230: train loss: 2.2825, val loss: 2.3624
step 1240: train loss: 2.2777, val loss: 2.3573
step 1250: train loss: 2.2698, val loss: 2.3616
step 1260: train loss: 2.2675, val loss: 2.3478
step 1270: train loss: 2.2695, val loss: 2.3489
step 1280: train loss: 2.2635, val loss: 2.3499
step 1290: train loss: 2.2469, val loss: 2.3455
step 1300: train loss: 2.2544, val loss: 2.3344
step 1310: train loss: 2.2539, val loss: 2.3451
step 1320: train loss: 2.2494, val loss: 2.3345
step 1330: train loss: 2.2433, val loss: 2.3335
step 1340: train loss: 2.2408, val loss: 2.3262
step 1350: train loss: 2.2322, val loss: 2.3297
step 1360: train loss: 2.2351, val loss: 2.3239
step 1370: train loss: 2.2289, val loss: 2.3295
step 1380: train loss: 2.2239, val loss: 2.3102
step 1390: train loss: 2.2251, val loss: 2.3102
step 1400: train loss: 2.2149, val loss: 2.3097
step 1410: train loss: 2.2197, val loss: 2.3076
step 1420: train loss: 2.2145, val loss: 2.3115
step 1430: train loss: 2.2055, val loss: 2.3141
step 1440: train loss: 2.2101, val loss: 2.3023
step 1450: train loss: 2.2015, val loss: 2.2922
step 1460: train loss: 2.1927, val loss: 2.2938
step 1470: train loss: 2.1981, val loss: 2.2863
step 1480: train loss: 2.1880, val loss: 2.2887
step 1490: train loss: 2.1865, val loss: 2.2854
step 1500: train loss: 2.1852, val loss: 2.2791
step 1510: train loss: 2.1718, val loss: 2.2807
step 1520: train loss: 2.1720, val loss: 2.2891
step 1530: train loss: 2.1697, val loss: 2.2765
step 1540: train loss: 2.1698, val loss: 2.2823
step 1550: train loss: 2.1714, val loss: 2.2775
step 1560: train loss: 2.1668, val loss: 2.2742
step 1570: train loss: 2.1604, val loss: 2.2746
step 1580: train loss: 2.1641, val loss: 2.2609
step 1590: train loss: 2.1558, val loss: 2.2606
step 1600: train loss: 2.1501, val loss: 2.2587
step 1610: train loss: 2.1519, val loss: 2.2632
step 1620: train loss: 2.1466, val loss: 2.2600
step 1630: train loss: 2.1431, val loss: 2.2576
step 1640: train loss: 2.1382, val loss: 2.2537
step 1650: train loss: 2.1432, val loss: 2.2544
step 1660: train loss: 2.1390, val loss: 2.2578
step 1670: train loss: 2.1266, val loss: 2.2524
step 1680: train loss: 2.1292, val loss: 2.2388
step 1690: train loss: 2.1186, val loss: 2.2463
step 1700: train loss: 2.1279, val loss: 2.2401
step 1710: train loss: 2.1274, val loss: 2.2461
step 1720: train loss: 2.1264, val loss: 2.2446
step 1730: train loss: 2.1109, val loss: 2.2388
step 1740: train loss: 2.1071, val loss: 2.2406
step 1750: train loss: 2.1068, val loss: 2.2327
step 1760: train loss: 2.1081, val loss: 2.2274
step 1770: train loss: 2.1043, val loss: 2.2296
step 1780: train loss: 2.0975, val loss: 2.2241
step 1790: train loss: 2.0989, val loss: 2.2231
step 1800: train loss: 2.0893, val loss: 2.2266
step 1810: train loss: 2.0907, val loss: 2.2239
step 1820: train loss: 2.0891, val loss: 2.2239
step 1830: train loss: 2.0889, val loss: 2.2127
step 1840: train loss: 2.0801, val loss: 2.2148
step 1850: train loss: 2.0750, val loss: 2.2092
step 1860: train loss: 2.0865, val loss: 2.2136
step 1870: train loss: 2.0727, val loss: 2.2181
step 1880: train loss: 2.0689, val loss: 2.2075
step 1890: train loss: 2.0678, val loss: 2.2008
step 1900: train loss: 2.0702, val loss: 2.1950
step 1910: train loss: 2.0651, val loss: 2.1985
step 1920: train loss: 2.0535, val loss: 2.2058
step 1930: train loss: 2.0561, val loss: 2.2003
step 1940: train loss: 2.0561, val loss: 2.1916
step 1950: train loss: 2.0524, val loss: 2.1937
step 1960: train loss: 2.0456, val loss: 2.1972
step 1970: train loss: 2.0414, val loss: 2.1957
step 1980: train loss: 2.0379, val loss: 2.1918
step 1990: train loss: 2.0389, val loss: 2.1903
step 2000: train loss: 2.0416, val loss: 2.1862
step 2010: train loss: 2.0393, val loss: 2.1971
step 2020: train loss: 2.0320, val loss: 2.1888
step 2030: train loss: 2.0263, val loss: 2.1861
step 2040: train loss: 2.0271, val loss: 2.1706
step 2050: train loss: 2.0212, val loss: 2.1730
step 2060: train loss: 2.0182, val loss: 2.1818
step 2070: train loss: 2.0138, val loss: 2.1810
step 2080: train loss: 2.0163, val loss: 2.1800
step 2090: train loss: 2.0162, val loss: 2.1662
step 2100: train loss: 1.9990, val loss: 2.1609
step 2110: train loss: 1.9989, val loss: 2.1730
step 2120: train loss: 2.0004, val loss: 2.1693
step 2130: train loss: 1.9951, val loss: 2.1632
step 2140: train loss: 1.9947, val loss: 2.1604
step 2150: train loss: 1.9863, val loss: 2.1700
step 2160: train loss: 1.9965, val loss: 2.1630
step 2170: train loss: 1.9852, val loss: 2.1705
step 2180: train loss: 1.9773, val loss: 2.1694
step 2190: train loss: 1.9759, val loss: 2.1542
step 2200: train loss: 1.9756, val loss: 2.1659
step 2210: train loss: 1.9705, val loss: 2.1594
step 2220: train loss: 1.9736, val loss: 2.1529
step 2230: train loss: 1.9615, val loss: 2.1595
step 2240: train loss: 1.9729, val loss: 2.1562
step 2250: train loss: 1.9669, val loss: 2.1529
step 2260: train loss: 1.9464, val loss: 2.1541
step 2270: train loss: 1.9625, val loss: 2.1486
step 2280: train loss: 1.9574, val loss: 2.1481
step 2290: train loss: 1.9478, val loss: 2.1529
step 2300: train loss: 1.9534, val loss: 2.1429
step 2310: train loss: 1.9457, val loss: 2.1405
step 2320: train loss: 1.9499, val loss: 2.1395
step 2330: train loss: 1.9361, val loss: 2.1429
step 2340: train loss: 1.9308, val loss: 2.1447
step 2350: train loss: 1.9331, val loss: 2.1371
step 2360: train loss: 1.9334, val loss: 2.1342
step 2370: train loss: 1.9379, val loss: 2.1422
step 2380: train loss: 1.9194, val loss: 2.1375
step 2390: train loss: 1.9316, val loss: 2.1393
step 2400: train loss: 1.9175, val loss: 2.1328
step 2410: train loss: 1.9169, val loss: 2.1394
step 2420: train loss: 1.9274, val loss: 2.1456
step 2430: train loss: 1.9097, val loss: 2.1290
step 2440: train loss: 1.9022, val loss: 2.1337
step 2450: train loss: 1.9145, val loss: 2.1314
step 2460: train loss: 1.9037, val loss: 2.1315
step 2470: train loss: 1.8946, val loss: 2.1275
step 2480: train loss: 1.8955, val loss: 2.1354
step 2490: train loss: 1.8915, val loss: 2.1338
step 2500: train loss: 1.8789, val loss: 2.1282
step 2510: train loss: 1.8799, val loss: 2.1239
step 2520: train loss: 1.8858, val loss: 2.1280
step 2530: train loss: 1.8838, val loss: 2.1371
step 2540: train loss: 1.8734, val loss: 2.1189
step 2550: train loss: 1.8755, val loss: 2.1312
step 2560: train loss: 1.8787, val loss: 2.1172
step 2570: train loss: 1.8783, val loss: 2.1316
step 2580: train loss: 1.8700, val loss: 2.1313
step 2590: train loss: 1.8678, val loss: 2.1194
step 2600: train loss: 1.8607, val loss: 2.1235
step 2610: train loss: 1.8607, val loss: 2.1215
step 2620: train loss: 1.8704, val loss: 2.1242
step 2630: train loss: 1.8528, val loss: 2.1270
step 2640: train loss: 1.8542, val loss: 2.1143
step 2650: train loss: 1.8482, val loss: 2.1186
step 2660: train loss: 1.8454, val loss: 2.1295
step 2670: train loss: 1.8516, val loss: 2.1064
step 2680: train loss: 1.8374, val loss: 2.1184
step 2690: train loss: 1.8383, val loss: 2.1196
step 2700: train loss: 1.8369, val loss: 2.1122
step 2710: train loss: 1.8288, val loss: 2.1170
step 2720: train loss: 1.8326, val loss: 2.1137
step 2730: train loss: 1.8302, val loss: 2.1115
step 2740: train loss: 1.8287, val loss: 2.1141
step 2750: train loss: 1.8182, val loss: 2.1203
step 2760: train loss: 1.8049, val loss: 2.1139
step 2770: train loss: 1.8106, val loss: 2.1059
step 2780: train loss: 1.8117, val loss: 2.1030
step 2790: train loss: 1.8042, val loss: 2.1052
step 2800: train loss: 1.8116, val loss: 2.1056
step 2810: train loss: 1.8100, val loss: 2.0949
step 2820: train loss: 1.8076, val loss: 2.1160
step 2830: train loss: 1.8075, val loss: 2.1129
step 2840: train loss: 1.7991, val loss: 2.1022
step 2850: train loss: 1.7944, val loss: 2.1054
step 2860: train loss: 1.7855, val loss: 2.1033
step 2870: train loss: 1.7948, val loss: 2.1086
step 2880: train loss: 1.7970, val loss: 2.1034
step 2890: train loss: 1.7768, val loss: 2.1114
step 2900: train loss: 1.7816, val loss: 2.1061
step 2910: train loss: 1.7755, val loss: 2.1130
step 2920: train loss: 1.7727, val loss: 2.1083
step 2930: train loss: 1.7680, val loss: 2.1036
step 2940: train loss: 1.7693, val loss: 2.0954
step 2950: train loss: 1.7658, val loss: 2.1123
step 2960: train loss: 1.7688, val loss: 2.1025
step 2970: train loss: 1.7574, val loss: 2.1042
step 2980: train loss: 1.7581, val loss: 2.0945
step 2990: train loss: 1.7585, val loss: 2.0922

Lalia the, is rad houn that thy seere'd ardfure,
Busince, as sich, bey;'s thugh many bay,
Tout's that thorught'se ald of son'd buless scan;
Hast ow may say'erow dy lgacke'd for shalst fou
ar no folir sphes; pet ow whe oher dit dlite bmatting,
Beaveraly king tis hacore oully. that I aghasre
burpet Godsy not bely be punt itue:
Lart dote his sluregh end thy track,
Whin fast fill lowse mat ory: jest theer sthally andsssep ellesk' be
Iw but of God vine-bye torure thingh faidcks
Whee I vin ushes vas s
